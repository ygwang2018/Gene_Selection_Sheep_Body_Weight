{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "def Polynomial_Algorithm(X_train,Y_train,s,tau,k_max):\n",
    "    sample_num,featur_num=X_train.shape\n",
    "    #初始化\n",
    "    corrlation=[]\n",
    "    for fea in range(featur_num):\n",
    "        corr=np.abs(np.dot(X_train[:,fea],Y_train.reshape(sample_num))/(np.sqrt(np.dot(X_train[:,fea],X_train[:,fea]))))\n",
    "        corrlation.append((fea,corr))\n",
    "    sort_cor=sorted(corrlation,key=lambda corrlation:corrlation[1],reverse=True)\n",
    "    Active_set=[]\n",
    "    for i in range(s):\n",
    "        Active_set.append(sort_cor[i][0])\n",
    "    Inactive_set=[i for i in range(featur_num)]\n",
    "    for del_fea in Active_set:\n",
    "        Inactive_set.remove(del_fea)\n",
    "    beta=np.dot(np.dot(np.linalg.inv(np.dot(X_train[:,Active_set].T,X_train[:,Active_set])),X_train[:,Active_set].T),Y_train)\n",
    "    erro=Y_train-np.dot(X_train[:,Active_set],beta)\n",
    "    d=np.dot(X_train[:,Inactive_set].T,erro)/sample_num\n",
    "    while True:\n",
    "        L=L_0=np.sum((Y_train-np.dot(X_train[:,Active_set],beta))**2)/(2*sample_num)\n",
    "        backward_sacrifice_lis=[]\n",
    "        forward_sacrifice_lis=[]\n",
    "        active_len=len(Active_set)\n",
    "        for i in range(active_len):\n",
    "            backward_sacrifice=np.dot(X_train[:,Active_set[i]],X_train[:,Active_set[i]])/(2*sample_num)*(beta[i,0])**2\n",
    "            backward_sacrifice_lis.append((backward_sacrifice,Active_set[i]))\n",
    "        for j in range(len(Inactive_set)):\n",
    "            mid=np.dot(X_train[:,Inactive_set[j]],X_train[:,Inactive_set[j]])\n",
    "            forward_sacrifice=(mid/(2*sample_num))*(d[j,0]/(mid/sample_num))**2\n",
    "            forward_sacrifice_lis.append((forward_sacrifice,Inactive_set[j]))\n",
    "        #从小到大排位    \n",
    "        backward_sacrifice_lis.sort(key=lambda backward_sacrifice_lis:backward_sacrifice_lis[0])\n",
    "        #从大到小排位\n",
    "        forward_sacrifice_lis.sort(key=lambda forward_sacrifice_lis:forward_sacrifice_lis[0],reverse=True)\n",
    "        for i in range(len(backward_sacrifice_lis)):\n",
    "            Active_set[i]=backward_sacrifice_lis[i][1]\n",
    "        for i in range(len(forward_sacrifice_lis)):\n",
    "            Inactive_set[i]=forward_sacrifice_lis[i][1]\n",
    "        #记录在k取值多少,最佳数据\n",
    "        trace_activ_set,trace_inactiv_set,trace_beta,trace_d=[],[],0,0\n",
    "        #k_max设置范围\n",
    "        for k in range(1,k_max+1):\n",
    "            new_active_set,new_inactive_set=copy.deepcopy(Active_set),copy.deepcopy(Inactive_set)\n",
    "            new_active_set[:k],new_inactive_set[:k]=new_inactive_set[:k],new_active_set[:k]\n",
    "            new_active_set,new_inactive_set=sorted(new_active_set),sorted(new_inactive_set)\n",
    "            new_beta=np.dot(np.dot(np.linalg.inv(np.dot(X_train[:,new_active_set].T,X_train[:,new_active_set])),X_train[:,new_active_set].T),Y_train) \n",
    "            new_erro=Y_train-np.dot(X_train[:,new_active_set],new_beta)\n",
    "            new_d=np.dot(X_train[:,new_inactive_set].T,erro)/sample_num\n",
    "            L_new=np.sum((Y_train-np.dot(X_train[:,new_active_set],new_beta))**2)/(2*sample_num)\n",
    "            if L_new<L:\n",
    "                trace_activ_set,trace_inactiv_set,trace_beta,trace_d=new_active_set,new_inactive_set,new_beta,new_d\n",
    "                L=L_new\n",
    "        if trace_activ_set:\n",
    "            beta,d,Active_set,Inactive_set=trace_beta,trace_d,trace_activ_set,trace_inactiv_set       \n",
    "        #print(L_0,L)\n",
    "        if L_0-L<tau:\n",
    "            break\n",
    "    return beta,Active_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (1,2,3,4,5,7,9,10,11,13,14,15,16,17,18,20,21,22,23,24,27,28,31,34,74,95,96,97,98,99,100,101,102,103,104,105,106,107,108,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,139,141,143,146,148,150,152,153,155,167,169,170,171,172,173,174,175,176,177,178,179,180,191,192,193,194,205,206,207,210,216,217,218,219,220,221,222,223,224,225,226,227,228) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"HuSheepData.csv\",encoding='gb18030')\n",
    "Weaning_Weight=np.array(data)[5,1:].astype(np.float64).reshape(240,1)\n",
    "Birth_Weight=np.array(data)[4,1:].astype(np.float64).reshape(240,1)\n",
    "Six_Weight=np.array(data)[6,1:].astype(np.float64).reshape(240,1)\n",
    "Featur_Sample=np.array(data)[8:,1:].astype(np.float64).T\n",
    "X_train=Featur_Sample[:170,:]\n",
    "X_test=Featur_Sample[170:,:]\n",
    "Birth_Weight_train=Birth_Weight[:170]\n",
    "Birth_Weight_test=Birth_Weight[170:]\n",
    "Six_Weight_train=Six_Weight[:170]\n",
    "Six_Weight_test=Six_Weight[170:]\n",
    "Weaning_Weight_train=Weaning_Weight[:170]\n",
    "Weaning_Weight_test=Weaning_Weight[170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "sampl_train_num,fea_train_num=X_train.shape\n",
    "sampl_test_num,fea_test_num=X_test.shape\n",
    "s_max=math.floor(sampl_train_num/(np.log(fea_train_num)*np.log(np.log(sampl_train_num))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#Weaning\n",
    "\n",
    "Weaning_best_SIC=float(\"inf\")\n",
    "Weaning_best_Active_set=[]\n",
    "Weaning_best_s=0\n",
    "for s in range(1,s_max+1):\n",
    "    tau_s=0.01*s*np.log(fea_train_num)*np.log(np.log(sampl_train_num))/sampl_train_num\n",
    "    beta_weaning,Active_set_weaning=Polynomial_Algorithm(X_train,Weaning_Weight_train,s,tau_s,s)\n",
    "    sor_weaning=sorted(Active_set_weaning)\n",
    "    \n",
    "    L=np.sum((Weaning_Weight_train-np.dot(X_train[:,sor_weaning],beta_weaning).reshape(sampl_train_num,1))**2)/sampl_train_num\n",
    "    SIC=sampl_train_num*np.log(L)+17*np.log(fea_train_num)*np.log(np.log(sampl_train_num))\n",
    "    if SIC<Weaning_best_SIC:\n",
    "        Weaning_best_SIC=SIC\n",
    "        Weaning_best_Active_set=Active_set_weaning\n",
    "        Weaning_best_s=s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf=SVR(kernel='rbf',C=0.1,gamma=0.01,epsilon=0.00001)\n",
    "sor_activ_weaning=sorted(Weaning_best_Active_set)\n",
    "clf.fit(X_train[:,sor_activ_weaning],Weaning_Weight_train.ravel())\n",
    "y_predict_weaning=clf.predict(X_test[:,sor_activ_weaning]).reshape(sampl_test_num,1)\n",
    "MSE_weaning=np.sum((y_predict_weaning-Weaning_Weight_test)**2)/sampl_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.899272614825463,\n",
       " [13215, 13542, 16547, 37188, 38773, 44785, 45225, 45759, 46836],\n",
       " 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_weaning,sor_activ_weaning,len(sor_activ_weaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#Six\n",
    "\n",
    "Six_best_SIC=float(\"inf\")\n",
    "Six_best_Active_set=[]\n",
    "Six_best_s=0\n",
    "for s in range(1,s_max+1):\n",
    "    tau_s=0.01*s*np.log(fea_train_num)*np.log(np.log(sampl_train_num))/sampl_train_num\n",
    "    beta_six,Active_set_six=Polynomial_Algorithm(X_train,Six_Weight_train,s,tau_s,s)\n",
    "    sor_six=sorted(Active_set_six)\n",
    "    \n",
    "    L=np.sum((Six_Weight_train-np.dot(X_train[:,sor_six],beta_six).reshape(sampl_train_num,1))**2)/sampl_train_num\n",
    "    SIC=sampl_train_num*np.log(L)+17*np.log(fea_train_num)*np.log(np.log(sampl_train_num))\n",
    "    if SIC<Six_best_SIC:\n",
    "        Six_best_SIC=SIC\n",
    "        Six_best_Active_set=Active_set_six\n",
    "        Six_best_s=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf=SVR(kernel='rbf',C=1,gamma=0.01,epsilon=0.01)\n",
    "sor_activ_six=sorted(Six_best_Active_set)\n",
    "clf.fit(X_train[:,sor_activ_six],Six_Weight_train.ravel())\n",
    "y_predict_six=clf.predict(X_test[:,sor_activ_six]).reshape(sampl_test_num,1)\n",
    "MSE_six=np.sum((y_predict_six-Six_Weight_test)**2)/sampl_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.818202610415639,\n",
       " [17742, 20566, 22981, 34251, 34419, 37402, 41705, 44603, 49587],\n",
       " 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_six,sor_activ_six,len(sor_activ_six)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#birth\n",
    "\n",
    "Birth_best_SIC=float(\"inf\")\n",
    "Birth_best_Active_set=[]\n",
    "Birth_best_s=0\n",
    "for s in range(1,s_max+1):\n",
    "    tau_s=0.01*s*np.log(fea_train_num)*np.log(np.log(sampl_train_num))/sampl_train_num\n",
    "    beta_birth,Active_set_Birth=Polynomial_Algorithm(X_train,Birth_Weight_train,s,tau_s,s)\n",
    "    sor_birth=sorted(Active_set_Birth)\n",
    "    \n",
    "    L=np.sum((Birth_Weight_train-np.dot(X_train[:,sor_birth],beta_birth).reshape(sampl_train_num,1))**2)/sampl_train_num\n",
    "    SIC=sampl_train_num*np.log(L)+17*np.log(fea_train_num)*np.log(np.log(sampl_train_num))\n",
    "    if SIC<Birth_best_SIC:\n",
    "        Birth_best_SIC=SIC\n",
    "        Birth_best_Active_set=Active_set_Birth\n",
    "        Birth_best_s=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf=SVR(kernel='rbf',C=0.1,gamma=0.01,epsilon=0.00001)\n",
    "sor_activ_Birth=sorted(Birth_best_Active_set)\n",
    "clf.fit(X_train[:,sor_activ_Birth],Birth_Weight_train.ravel())\n",
    "y_predict_Birth=clf.predict(X_test[:,sor_activ_Birth]).reshape(sampl_test_num,1)\n",
    "MSE_Birth=np.sum((y_predict_Birth-Birth_Weight_test)**2)/sampl_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22917819206362613,\n",
       " [2804, 14042, 15285, 19981, 34991, 43026, 44841, 45759, 53344],\n",
       " 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_Birth,sor_activ_Birth,len(sor_activ_Birth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=np.array(data)[:,0]\n",
    "gene_name=col[8:]\n",
    "gene=pd.DataFrame(gene_name[sor_activ_Birth])\n",
    "gene.to_csv(\"best_gene_birth_PA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene=pd.DataFrame(gene_name[sor_activ_six])\n",
    "gene.to_csv(\"best_gene_six_PA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene=pd.DataFrame(gene_name[sor_activ_weaning])\n",
    "gene.to_csv(\"best_gene_weaning_PA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
